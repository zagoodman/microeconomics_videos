{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Read-data\" data-toc-modified-id=\"Read-data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Read data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Dictionaries-shared-across-tables\" data-toc-modified-id=\"Dictionaries-shared-across-tables-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Dictionaries shared across tables</a></span></li></ul></li><li><span><a href=\"#Covariate-balance\" data-toc-modified-id=\"Covariate-balance-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Covariate balance</a></span></li><li><span><a href=\"#Post-double-selection-control-variable-selection\" data-toc-modified-id=\"Post-double-selection-control-variable-selection-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Post-double-selection control variable selection</a></span><ul class=\"toc-item\"><li><span><a href=\"#Table:-description-of-eligible-control-vars\" data-toc-modified-id=\"Table:-description-of-eligible-control-vars-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Table: description of eligible control vars</a></span></li><li><span><a href=\"#Table:-control-variables-for-ITT-PDS\" data-toc-modified-id=\"Table:-control-variables-for-ITT-PDS-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Table: control variables for ITT PDS</a></span></li><li><span><a href=\"#Table:-control-variables-for-LATE-PDS\" data-toc-modified-id=\"Table:-control-variables-for-LATE-PDS-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Table: control variables for LATE PDS</a></span></li></ul></li><li><span><a href=\"#ITT-coefficient-estimates\" data-toc-modified-id=\"ITT-coefficient-estimates-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>ITT coefficient estimates</a></span><ul class=\"toc-item\"><li><span><a href=\"#Table:-first-stage\" data-toc-modified-id=\"Table:-first-stage-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Table: first stage</a></span></li><li><span><a href=\"#Table:-second-stage\" data-toc-modified-id=\"Table:-second-stage-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Table: second stage</a></span></li><li><span><a href=\"#Table:-spillovers-to-grades\" data-toc-modified-id=\"Table:-spillovers-to-grades-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Table: spillovers to grades</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.options.display.max_columns = 50\n",
    "pd.options.display.max_rows = 100\n",
    "pd.options.display.max_colwidth = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/generated/pds_coeffs.csv')\n",
    "print(df.dtypes)\n",
    "print(df.isnull().sum())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dff = pd.read_csv('../data/generated/itt_coeffs.csv')\n",
    "print(dff.dtypes)\n",
    "print(dff.isnull().sum())\n",
    "dff.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dflate = pd.read_csv('../data/generated/lates_coeffs.csv')\n",
    "print(dflate.dtypes)\n",
    "print(dflate.isnull().sum())\n",
    "dflate.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfiv = pd.read_csv('../data/generated/pds_iv_coeffs.csv')\n",
    "print(dfiv.dtypes)\n",
    "print(dfiv.isnull().sum())\n",
    "dfiv.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dictionaries shared across tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eligible control variables\n",
    "ctrl_dict = {\n",
    "    'Midterm 1 score': 'Score on the first midterm',\n",
    "    'Year = 2019': '1 if course taken in 2019, 0 otherwise',\n",
    "    'Cumulative GPA': 'Cumulative GPA from prior term, 0 if not observed',\n",
    "    'No cum. GPA': '1 if Cumulative GPA unobserved, 0 otherwise',\n",
    "    'Math quiz score': 'Score on a quiz assessing prerequisite math skills',\n",
    "    'PSET visits': 'Number of PSET visits as of the first midterm',\n",
    "    'Videos watched': 'Number unique videos watched as of the first midterm',\n",
    "    'Hours videos': 'Hours of unique videos watched as of the first midterm',\n",
    "    'Asian': '1 if ethnicity is Asian, 0 otherwise',\n",
    "    'Latinx': '1 if ethnicity is Latinx, 0 otherwise',\n",
    "    'White': '1 if ethnicity is White, 0 otherwise',\n",
    "    'Female': '1 if female, 0 otherwise',\n",
    "    'Transfer': '1 if transfer student, 0 otherwise'\n",
    "}\n",
    "\n",
    "# variable names\n",
    "name_dict = {'attendance': 'Attendance',\n",
    "             'duration_final': 'Hours videos by Final',\n",
    "             'duration_final_u': 'Hours unique videos by Final',\n",
    "             'duration_mid2': 'Hours videos by Mid. 2',\n",
    "             'duration_mid2_u': 'Hours unique videos by Mid. 2',\n",
    "             'duration_u_b': 'Hours unique videos, winter',\n",
    "             'final_100b': 'Final exam score, winter',\n",
    "             'finalscorestd': 'Final exam score',\n",
    "             'gpa_econ_sans100a': 'Econ classes ex. Micro A',\n",
    "             'gpa_letter': 'All classes',\n",
    "             'gpa_letter_sans100a': 'Excluding Micro A',\n",
    "             'gpa_letter_sansecon': 'Excluding econ classes',\n",
    "             'letter_option': 'Letter grade in Micro A',\n",
    "             'mid1bscorestd': 'Midterm 1 score, Micro B',\n",
    "             'mid2bscorestd': 'Midterm 2 score, Micro B',\n",
    "             'mid2scorestd': 'Midterm 2 score',\n",
    "             'nclass_letter': 'Num. classes taken for letter',\n",
    "             'nclass_np': 'Num. classes not passed',\n",
    "             'nclass_p': 'Num. classes passed',\n",
    "             'nclass_pnp': 'Num. classes taken P/NP',\n",
    "             'nclass_w': 'Num. classes withdrawn',\n",
    "             'pclass_letter': '\\% classes taken for letter',\n",
    "             'pclass_pnp': '\\% classes taken P/NP',\n",
    "             'piazza_answers': 'Num. Piazza answers',\n",
    "             'piazza_daysonline': 'Num. Piazza days online',\n",
    "             'piazza_questions': 'Num. Piazza questions asked',\n",
    "             'piazza_views': 'Num. Piazza views',\n",
    "             'pset_post': 'Num. of PSET visits',\n",
    "             'took100b': 'Took 100B for a letter grade',\n",
    "             'units_letter': 'Num. units taken for letter grade',\n",
    "             'units_pnp': 'Num. units taken P/NP',\n",
    "             'units_w': 'Num. units withdrawn',\n",
    "             'videos_final': 'Num. videos before Final',\n",
    "             'videos_final_u': 'Num. unique videos before Final',\n",
    "             'videos_mid2': 'Num. videos before Mid. 2',\n",
    "             'videos_mid2_u': 'Num. unique videos before Mid. 2',\n",
    "             'videos_u_b': 'Num. unique videos, winter',\n",
    "             'winter_gpa_econ_sans100a': 'Term GPA, econ courses ex. Micro B, winter',\n",
    "             'winter_gpa_letter': 'Term GPA, winter',\n",
    "             'winter_gpa_letter_sans100a': 'Term GPA, ex. Micro B',\n",
    "             'winter_gpa_letter_sansecon': 'Term GPA, ex. econ courses',\n",
    "             'winter_nclass_letter': 'Num. classes taken for letter',\n",
    "             'winter_nclass_np': 'Num. classes not passed',\n",
    "             'winter_nclass_p': 'Num. classes passed',\n",
    "             'winter_nclass_pnp': 'Num. classes taken P/NP',\n",
    "             'winter_nclass_w': 'Num. classes withdrawn',\n",
    "             'winter_pclass_letter': '\\% classes taken for letter',\n",
    "             'winter_pclass_pnp': '\\% classes taken P/NP',\n",
    "             'winter_units_letter': 'Num. units taken for letter grade',\n",
    "             'winter_units_pnp': 'Num. units taken P/NP',\n",
    "             'winter_units_w': 'Num. units withdrawn',\n",
    "             'asian': 'Asian',\n",
    "             'duration_mid1': 'Hours videos',\n",
    "             'duration_mid1_u': 'Hours videos, unique',\n",
    "             'female': 'Female',\n",
    "             'latx': 'Latinx',\n",
    "             'male': 'Male',\n",
    "             'mathquizstd': 'Math quiz score',\n",
    "             'mid1scorestd': 'Midterm 1 score',\n",
    "             'othereth': 'Other ethnicity',\n",
    "             'prev_cumgpa': 'Cumulative GPA',\n",
    "             'prev_cumgpa_unobs': 'No cum. GPA',\n",
    "             'pset_pre': 'PSET visits',\n",
    "             'transfer': 'Transfer',\n",
    "             'white': 'White',\n",
    "             'videos_mid1': 'Videos watched',\n",
    "             'videos_mid1_u': 'Videos, unique',\n",
    "             'y2019': 'Year = 2019'\n",
    "}\n",
    "\n",
    "# variables appearing in which table\n",
    "table_dict = {'attendance': 4,\n",
    "             'duration_final': 1,\n",
    "             'duration_final_u': 1,\n",
    "             'duration_mid2': 1,\n",
    "             'duration_mid2_u': 1,\n",
    "             'duration_u_b': 5,\n",
    "             'final_100b': 5,\n",
    "             'finalscorestd': 2,\n",
    "             'gpa_econ_sans100a': 3,\n",
    "             'gpa_letter': 3,\n",
    "             'gpa_letter_sans100a': 3,\n",
    "             'gpa_letter_sansecon': 3,\n",
    "             'letter_option': 3,\n",
    "             'mid1bscorestd': 5,\n",
    "             'mid2bscorestd': 5,\n",
    "             'mid2scorestd': 2,\n",
    "             'nclass_letter': 3,\n",
    "             'nclass_np': 3,\n",
    "             'nclass_p': 3,\n",
    "             'nclass_pnp': 3,\n",
    "             'nclass_w': 3,\n",
    "             'pclass_letter': 3,\n",
    "             'pclass_pnp': 3,\n",
    "             'piazza_answers': 4,\n",
    "             'piazza_daysonline': 4,\n",
    "             'piazza_questions': 4,\n",
    "             'piazza_views': 4,\n",
    "             'pset_post': 4,\n",
    "             'took100b': 5,\n",
    "             'units_letter': 3,\n",
    "             'units_pnp': 3,\n",
    "             'units_w': 3,\n",
    "             'videos_final': 1,\n",
    "             'videos_final_u': 1,\n",
    "             'videos_mid2': 1,\n",
    "             'videos_mid2_u': 1,\n",
    "             'videos_u_b': 5,\n",
    "             'winter_gpa_econ_sans100a': 5,\n",
    "             'winter_gpa_letter': 5,\n",
    "             'winter_gpa_letter_sans100a': 5,\n",
    "             'winter_gpa_letter_sansecon': 5,\n",
    "             'winter_nclass_letter': 5,\n",
    "             'winter_nclass_np': 5,\n",
    "             'winter_nclass_p': 5,\n",
    "             'winter_nclass_pnp': 5,\n",
    "             'winter_nclass_w': 5,\n",
    "             'winter_pclass_letter': 5,\n",
    "             'winter_pclass_pnp': 5,\n",
    "             'winter_units_letter': 5,\n",
    "             'winter_units_pnp': 5,\n",
    "             'winter_units_w': 5,\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Covariate balance\n",
    "\n",
    "Create table showing balance across treatment arms on observables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "\n",
    "dfbal = pd.read_csv('../data/generated/balance_table_data.csv')\n",
    "\n",
    "# stack mean, stderr, N\n",
    "dfbal = dfbal.melt(['exam', 'depvar', 'arm', 'bothpairs'], var_name='stat', value_name='value')\n",
    "dfbal.stat.replace({'mean': '1mean', 'stderr': '2stderr', 'N': '3N'}, inplace=True)\n",
    "\n",
    "# widen using combinations of arm-bothpairs within exam-depvar\n",
    "dfbal['combo'] = (dfbal.bothpairs + 1) * 10 + dfbal.arm\n",
    "dfbal.drop(['arm', 'bothpairs'], 1, inplace=True)\n",
    "dfbal = dfbal.set_index(['exam', 'depvar', 'stat', 'combo']).unstack().reset_index()\n",
    "dfbal.columns = dfbal.columns.droplevel(0)\n",
    "dfbal.columns = ['exam', 'depvar', 'stat', 'above_med', 'ctrl_all', 'treat_all', 'ctrl_both', 'treat_both']\n",
    "\n",
    "# sort depvar by 'sorter'\n",
    "sorter = ['mid1scorestd', 'y2019', 'prev_cumgpa', 'prev_cumgpa_unobs', \n",
    "          'mathquizstd', 'pset_pre', 'videos_mid1', 'videos_mid1_u', \n",
    "          'duration_mid1', 'duration_mid1_u', 'asian', 'latx', 'white', \n",
    "          'othereth', 'female', 'male', 'transfer']\n",
    "# Create the dictionary that defines the order for sorting\n",
    "sorterIndex = dict(zip(sorter, range(len(sorter))))\n",
    "# Generate a rank column \n",
    "dfbal['depvar_rk'] = dfbal.depvar.map(sorterIndex)\n",
    "# sort\n",
    "dfbal.sort_values(['exam', 'depvar_rk', 'stat'], ascending=[False, True, True], inplace=True)\n",
    "\n",
    "# insert p-value columns\n",
    "from scipy.stats import t\n",
    "def get_p_value(meant, meanc, stderrt, stderrc, Nt, Nc):\n",
    "    \"\"\"\n",
    "    Returns a p-value for a given set of stats.\n",
    "    t = treated\n",
    "    c = control\n",
    "    Does not assume equal variance (Welch's t-test).\n",
    "    \"\"\"\n",
    "    # calculate t statistic\n",
    "    tcrit = abs(meant - meanc) / (np.sqrt(stderrt**2 + stderrc**2))\n",
    "    # calculate degrees of freedom (conservative, i.e. more likely to reject balance)\n",
    "    d_o_f = Nt + Nc - 2\n",
    "    return t.sf(tcrit, d_o_f) * 2\n",
    "dfbal.insert(6, 'p_all', 0)\n",
    "dfbal.insert(9, 'p_both', 0)\n",
    "for i in range(int(len(dfbal)/3)):\n",
    "    rown = i*3\n",
    "    for k in ['all', 'both']:\n",
    "        meant = dfbal.loc[rown, 'treat_' + k]\n",
    "        meanc = dfbal.loc[rown, 'ctrl_' + k]\n",
    "        stderrt = dfbal.loc[rown + 1, 'treat_' + k]\n",
    "        stderrc = dfbal.loc[rown + 1, 'ctrl_' + k]\n",
    "        Nt = dfbal.loc[rown + 2, 'treat_' + k]\n",
    "        Nc = dfbal.loc[rown + 2, 'ctrl_' + k]\n",
    "        dfbal.loc[3*i, 'p_' + k] = get_p_value(meant, meanc, stderrt, stderrc, Nt, Nc)\n",
    "\n",
    "# get stars\n",
    "def star_p(x):\n",
    "    \"\"\"\n",
    "    Adds stars to p, a p-value.\n",
    "    \"\"\"\n",
    "    if x > 0.1:\n",
    "        return '{:.3f}'.format(x)\n",
    "    elif x > 0.05:\n",
    "        return '{:.3f}*'.format(x)\n",
    "    elif x > 0.01:\n",
    "        return '{:.3f}**'.format(x)\n",
    "    elif x > 0.001:\n",
    "        return '{:.3f}***'.format(x)\n",
    "    else:\n",
    "        print(\"check your work\")\n",
    "        return '{:.3f}***'.format(x)\n",
    "for k in ['all', 'both']:\n",
    "    dfbal['p_' + k] = dfbal.apply(lambda x: star_p(x['p_' + k]) if x['stat'] == '1mean' else '', 1)\n",
    "    \n",
    "# Remove all N's except last one for each exam\n",
    "keepidx = dfbal.groupby('exam', as_index=False).stat.nth(-1).index\n",
    "dfbal = dfbal.loc[(dfbal.stat != '3N') | (dfbal.index.isin(keepidx))]\n",
    "\n",
    "# Rename depvars and duplicates\n",
    "dfbal['og'] = dfbal['depvar'].copy()\n",
    "dfbal['depvar'] = dfbal.depvar.apply(lambda x: name_dict.get(x))\n",
    "# dfbal['depvar'] = dfbal.depvar.apply(lambda x: '\\\\indentrow{' + name_dict.get(x) + '}')\n",
    "dropidx = dfbal.groupby(['exam', 'depvar'], as_index=False).stat.nth(1).index\n",
    "dfbal.loc[dropidx, 'depvar'] = ''\n",
    "dfbal.loc[dfbal.stat == '3N', 'depvar'] = 'Observations'    \n",
    "\n",
    "# stringify stat values\n",
    "for v in ['above_med', 'ctrl_all', 'treat_all', 'ctrl_both', 'treat_both']:\n",
    "    dfbal.loc[dfbal.stat == '1mean', v] = \\\n",
    "        dfbal.loc[dfbal.stat == '1mean', v].apply(lambda x: '{:.3f}'.format(x))\n",
    "    dfbal.loc[dfbal.stat == '2stderr', v] = \\\n",
    "        dfbal.loc[dfbal.stat == '2stderr', v].apply(lambda x: '({:.3f})'.format(x))\n",
    "    dfbal.loc[dfbal.stat == '3N', v] = \\\n",
    "        dfbal.loc[dfbal.stat == '3N', v].apply(lambda x: str(int(x)))\n",
    "    \n",
    "    \n",
    "# remove unnecessary cols, colnames\n",
    "dfbal = dfbal.drop(['og', 'stat', 'depvar_rk'], 1)\n",
    "dfbal.rename(columns={'depvar': 'Variable', \n",
    "              'above_med': 'Above Median',\n",
    "              'ctrl_all': 'Control',\n",
    "              'treat_all': 'Incentive',\n",
    "              'ctrl_both': 'Control',\n",
    "              'treat_both': 'Incentive',\n",
    "              'p_all': '(3) - (2)',\n",
    "              'p_both': '(5) - (4)'}, inplace=True)\n",
    "\n",
    "display(dfbal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define latex function\n",
    "\n",
    "def convert_to_latex(dft, column_format, caption, label, note='', \n",
    "                     observations=True, longtable=False, scalewidth=True, stars=True, regnote=True):\n",
    "    '''\n",
    "    Takes dataframe dft and spits out tex table given options.\n",
    "    \n",
    "    Arguments\n",
    "    ---------\n",
    "    : dft - dataframe ready to become a tex table. Column names are correct.\n",
    "    : column_format - tabular columns\n",
    "    : caption - title of the table\n",
    "    : label - tex ref to add to table\n",
    "    : note - note at the bottom of the table\n",
    "    : observations - if True, adds a line above the observations count\n",
    "    : longtable - if True, adds longtable environment (default False). \n",
    "        Currently cannot both longtable and scalewidth.\n",
    "    : scalewidth - if True, scales the table to fit the tex linewidth\n",
    "    : stars - if True, wraps * in \\\\sym{}\n",
    "    : regnote - if True, adds \\Regnote to note. Ignored if longtable.\n",
    "    '''\n",
    "    assert isinstance(dft, pd.core.frame.DataFrame)\n",
    "    for var in [column_format, caption, label, note]:\n",
    "        assert isinstance(var, str)\n",
    "    for var in [observations, longtable, scalewidth, stars, regnote]:\n",
    "        assert isinstance(var, bool)\n",
    "    assert not (longtable and scalewidth)\n",
    "    pass\n",
    "    \n",
    "    if not longtable:\n",
    "        # convert to tex\n",
    "        t = dft.to_latex(index=False, escape=False,\n",
    "                       column_format=column_format)\n",
    "        # add caption (title) and reference label to table\n",
    "        addendum = '\\\\begin{spacing}{1.0} \\n' +\\\n",
    "            '\\\\begin{table} \\\\centering \\\\caption{' + caption + '} \\n' +\\\n",
    "            '\\\\label{' + label + '} \\n'\n",
    "        if scalewidth:\n",
    "            addendum += '\\\\resizebox{\\linewidth}{!}{% \\n'\n",
    "        addendum += '\\\\begin{threeparttable} \\n'\n",
    "        t = addendum + t\n",
    "\n",
    "        # add notes to the bottom\n",
    "        if regnote:\n",
    "            addendum = '\\\\Fignote{' + note + ' \\\\Regnote} \\n\\\\end{threeparttable}' \n",
    "        else:\n",
    "            addendum = '\\\\Fignote{' + note + '} \\n\\\\end{threeparttable}' \n",
    "        if scalewidth:\n",
    "            addendum += '}'\n",
    "        addendum += '\\n\\\\end{table} \\n\\\\end{spacing}'\n",
    "        t = t + addendum\n",
    "        \n",
    "    else:\n",
    "        # convert to tex\n",
    "        t = dft.to_latex(index=False, escape=False, longtable=True, \n",
    "                         caption=caption, label=label, \n",
    "                         column_format=column_format)\n",
    "\n",
    "        # add caption (title) and reference label to table\n",
    "        addendum = '\\\\begin{spacing}{1.0} \\n' +\\\n",
    "                   '\\\\begin{ThreePartTable} \\n' +\\\n",
    "                   '\\\\begin{TableNotes} \\n' +\\\n",
    "                   '\\\\item \\\\textit{Note}: ' + note + '\\n' +\\\n",
    "                   '\\\\end{TableNotes} \\n' +\\\n",
    "                   '\\\\footnotesize \\n \\\\begin{longtable}'\n",
    "        t = t.replace('\\\\begin{longtable}', addendum)\n",
    "        \n",
    "        # replace endhead with endfirsthead\n",
    "        t = t.replace('\\\\endhead', '\\\\endfirsthead')\n",
    "        \n",
    "        # add header on subsequent pages with 'Table X continued'\n",
    "        ncols = len(dft.columns)\n",
    "        startidx = t.find('\\\\endfirsthead')\n",
    "        addendum = '\\\\endfirsthead \\n' +\\\n",
    "            '\\multicolumn{' + str(ncols) + '}{r}{{Table \\\\ref{' + label + '} (continued)}} \\\\\\\\' +\\\n",
    "            '\\n\\\\toprule \\n \\\\endhead'\n",
    "        t = t[:startidx] + addendum + t[startidx + 13:]\n",
    "\n",
    "        # add notes to the bottom\n",
    "        startidx = t.find('\\\\endlastfoot')\n",
    "        t = t[:startidx] + '\\\\insertTableNotes \\n' + t[startidx:]\n",
    "        \n",
    "        # close out TPT and spacing\n",
    "        t += '\\n\\\\end{ThreePartTable} \\n\\\\end{spacing}'\n",
    "    \n",
    "    # insert \\sym{} around stars\n",
    "    if stars:\n",
    "        t = t.replace('*** ', '\\\\sym{***} ')\n",
    "        t = t.replace('** ', '\\\\sym{**} ')\n",
    "        t = t.replace('* ', '\\\\sym{*} ')\n",
    "        \n",
    "    # add line above N, if N\n",
    "    if observations:\n",
    "        pos = t.find('Observations')\n",
    "        if pos > -1:\n",
    "            t = t[:pos] + '\\\\midrule \\n ' + t[pos:]\n",
    "        \n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get subset and convert to tex\n",
    "\n",
    "btable_mid = dfbal.loc[dfbal.exam == 'mid2'].drop('exam', 1)\n",
    "btable_fin = dfbal.loc[dfbal.exam == 'final'].drop('exam', 1)\n",
    "\n",
    "# convert to latex\n",
    "\n",
    "column_format='m{0.25\\\\linewidth} *{7}{>{\\\\centering\\\\arraybackslash}m{0.095\\\\linewidth}}'\n",
    "caption = ['Baseline balance test, Midterm 2 sample', \n",
    "           'Baseline balance test, Final Exam sample']\n",
    "label = ['balance_table_mid2', 'balance_table_final']\n",
    "note = 'This table includes all students who completed the insert_exam. ' +\\\n",
    "        'Descriptions of each variable can be found in Table \\\\ref{controlvars_desc}. ' +\\\n",
    "        '\\\\textit{Male} and \\\\textit{Female} do not include nine students who do not report ' +\\\n",
    "        'a gender. \\\\textit{P-values} are reported for the Welch\\'s t-test of equal means between ' +\\\n",
    "        'the \\\\textit{Control} and \\\\textit{Incentive} arms.'\n",
    "note = [note.replace('insert_exam', 'second midterm'), \n",
    "       note.replace('insert_exam', 'final exam')]\n",
    "\n",
    "for i, k in enumerate([btable_mid, btable_fin]):\n",
    "    \n",
    "    k = convert_to_latex(k, column_format, caption[i], label[i], note[i])\n",
    "    \n",
    "    # Add additional column labels\n",
    "    k = k.replace('\\\\toprule', '\\\\toprule \\n & \\\\multicolumn{3}{c}{All students} & P-values & '+\\\n",
    "                  '\\\\multicolumn{2}{c}{Matched pairs}  & P-values  \\\\\\ \\n ' +\\\n",
    "                  '\\\\cmidrule(lr){2-4}\\\\cmidrule(lr){6-7} \\n', 1)\n",
    "\n",
    "    # space out variables\n",
    "    for v in [x for x in dfbal.Variable.unique() if x not in ['', 'Observations']]:\n",
    "        k = k.replace(v + ' &', '\\\\customlinespace ' + v + ' &')\n",
    "\n",
    "    # write to tex file\n",
    "    with open('../tex/tables/' + label[i] + '.tex', 'w') as tf:\n",
    "         tf.write(k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post-double-selection control variable selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: description of eligible control vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct dict\n",
    "\n",
    "ctrls = ['Midterm 1 score', 'Year = 2019', 'Cumulative GPA',\n",
    "    'No cum. GPA', 'Math quiz score', 'PSET visits', \n",
    "    'Videos watched', 'Hours videos', 'Asian', 'Latinx',\n",
    "    'White', 'Female', 'Transfer']\n",
    "\n",
    "dfc = pd.DataFrame(data={'Variable': ctrls, \n",
    "                         'Description': [ctrl_dict.get(x) for x in ctrls]})\n",
    "display(dfc.head())\n",
    "\n",
    "# translate to tex\n",
    "\n",
    "column_format='p{0.3\\linewidth} p{0.6\\linewidth}'\n",
    "caption = 'Candidate control variables for post-double-selection'\n",
    "label = 'controlvars_desc'\n",
    "note = '\\\\textit{Midterm 1 score} and \\\\textit{Math quiz score} are measured in control standard deviations. ' +\\\n",
    "    '\\\\textit{Cumulative GPA} is measured on a 4.0 scale. Videos included in \\\\textit{Videos watched} and ' +\\\n",
    "    '\\\\textit{Hours videos} are unique course-relevant videos. The ethnicity variables are coded by university ' +\\\n",
    "    'records: \\\\textit{Asian} includes \"Chinese/Chinese American\", \"Vietnamese\", \"East Indian/Pakistani\", ' +\\\n",
    "    '\"Japanese/Japanese American\", \"Korean/Korean American\", and \"All other Asian/Asian American\"; \\\\textit{Latinx} ' +\\\n",
    "    'includes \"Mexican/Mexican American\", \"Chicano\", and \"All other Spanish-American/Latino\"; \\\\textit{White} ' +\\\n",
    "    'includes \"White/Caucasian\"; and the omitted category inludes \"African American/Black\", \"Pacific Islander\", ' +\\\n",
    "    'and \"Not give/declined to state\".'\n",
    "\n",
    "table0 = convert_to_latex(dfc, column_format, caption, label, note, scalewidth=False, regnote=False)\n",
    "\n",
    "# write to tex file\n",
    "with open('../tex/tables/controlvars_desc.tex', 'w') as tf:\n",
    "     tf.write(table0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: control variables for ITT PDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first reshape wide\n",
    "dfw = df[['depvar', 'model', 'ctrls']].set_index(['depvar', 'model']).unstack().reset_index()\n",
    "dfw.columns = dfw.columns.droplevel(0)\n",
    "dfw.columns = ['Dependent Variable', 'Controls,\\newline Fixed Effects', 'Controls,\\newline All Observations']\n",
    "dfw = dfw.iloc[:, [0, 2, 1]]\n",
    "dfw['og'] = dfw.iloc[:, 0].copy()\n",
    "dfw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctrls = [x for x in dfw.iloc[:,2].unique()]\n",
    "ctrls += [x for x in dfw.iloc[:,1].unique() if x not in ctrls]\n",
    "ctrls = [str(x).split(' ') for x in ctrls]\n",
    "ctrls = [j for i in ctrls for j in i]\n",
    "ctrls = list(dict.fromkeys(ctrls))\n",
    "for x in ['nan']:\n",
    "    ctrls.remove(x) \n",
    "ctrls.sort()\n",
    "ctrls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relabel variables with publication-ready names\n",
    "\n",
    "for i in range(0,3):\n",
    "    print(i)\n",
    "    dfw.iloc[:,i] = dfw.iloc[:,i].apply(lambda x: sorted([name_dict.get(k) or 'None' for k in str(x).split(' ')]) or x)\n",
    "    dfw.iloc[:,i] = dfw.iloc[:,i].apply(lambda x: ('\\newline ').join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add Table labels\n",
    "\n",
    "# tables:\n",
    "# 1 - first stage\n",
    "# 2 - second stage\n",
    "# 3 - spillovers to grades\n",
    "# 4 - spillovers to study methods\n",
    "# 5 - spillovers to following quarter\n",
    "\n",
    "dfw['Table'] = dfw.og.apply(lambda x: 'Table {}'.format(str(table_dict.get(x))))\n",
    "dfw.sort_values(['Table', dfw.columns[0]], inplace=True)\n",
    "\n",
    "# set Table 'index' as first column\n",
    "dfw['Table'] = dfw['Table'].mask(dfw['Table'].duplicated(),'')\n",
    "dfw = dfw.loc[:, ['Table'] + [c for c in dfw.columns if c != 'Table']]\n",
    "dfw.reset_index(inplace=True, drop=True)\n",
    "\n",
    "display(dfw.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: get subset of models in paper\n",
    "\n",
    "# get subset and convert to tex\n",
    "table1vars = dfw.og.unique() # change this\n",
    "table1 = dfw.loc[dfw.og.isin(table1vars), dfw.columns[:-1]]\n",
    "\n",
    "# shorten variable descriptions\n",
    "for c in table1.columns[-2:]:\n",
    "    table1.loc[table1[c].str.contains(', unique'), c] = \\\n",
    "        table1.loc[table1[c].str.contains(', unique'), c].apply(lambda x: x.replace(', unique', ''))\n",
    "\n",
    "display(table1.head())\n",
    "\n",
    "\n",
    "# convert to latex\n",
    "\n",
    "column_format= 'p{0.07\\linewidth} >{\\hangindent=1em}p{0.38\\linewidth} '+\\\n",
    "                         'p{0.22\\linewidth} p{0.22\\linewidth}'\n",
    "caption = 'ITT model controls selected via post-double-selection'\n",
    "label = 'controlvars_selected_itt'\n",
    "note = 'Controls chosen via the PDS procedure of \\\\textcite{bch2014a}. ' +\\\n",
    "    'In the \\\\textit{All Observations} model, \\\\textit{Midterm 1 score} and \\\\textit{Year = 2019} are ' +\\\n",
    "    'additionally included as controls. In the \\\\textit{Fixed Effects} model, pair fixed effects ' +\\\n",
    "    'and \\\\textit{Midterm 1 score} are included. ' +\\\n",
    "    'All control variables are measured before the start of the experiment, e.g. \\\\textit{Hours videos} is ' +\\\n",
    "    'the hours of videos watched as of the first midterm.'\n",
    "\n",
    "table1 = convert_to_latex(table1, column_format, caption, label, note, \n",
    "                          observations=False, longtable=True, stars=False, scalewidth=False)\n",
    "\n",
    "# add horizontal lines betweeen groups\n",
    "for i in range(2, 6):\n",
    "    table1 = table1.replace('Table {}'.format(str(i)), \n",
    "                            '\\\\midrule \\n Table {}'.format(str(i)), 1)\n",
    "    \n",
    "# write to tex file\n",
    "with open('../tex/tables/controlvars_selected_itt.tex', 'w') as tf:\n",
    "     tf.write(table1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: control variables for LATE PDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first reshape wide\n",
    "dfw = dfiv.copy()\n",
    "\n",
    "# mark instruments\n",
    "dfw['endog'] = dfw.model.apply(lambda x: x[-1])\n",
    "\n",
    "# rename models FE or not\n",
    "dfw['model'] = dfw.model.apply(lambda x: x[:-2])\n",
    "\n",
    "# reshape wide\n",
    "dfw = dfw[['depvar', 'model', 'endog', 'ctrls']].set_index(['depvar', 'endog', 'model']).unstack().reset_index()\n",
    "dfw.columns = dfw.columns.droplevel(0)\n",
    "dfw.columns = ['Dependent Variable', 'Instrumented', 'Controls,\\newline Fixed Effects', 'Controls,\\newline All Observations']\n",
    "\n",
    "# rename instruments\n",
    "dfw.Instrumented.replace({'d': 'duration_mid1_u', 'v': 'videos_mid1_u'}, inplace=True)\n",
    "\n",
    "# order columns, copy og varnames\n",
    "dfw = dfw.iloc[:, [0, 1, 3, 2]]\n",
    "dfw['og'] = dfw.iloc[:, 0].copy()\n",
    "\n",
    "# replace varnames with publishable names\n",
    "for i in range(0,4):\n",
    "    dfw.iloc[:,i] = dfw.iloc[:,i].apply(lambda x: sorted([name_dict.get(k) or 'None' for k in str(x).split(' ')]) or x)\n",
    "    dfw.iloc[:,i] = dfw.iloc[:,i].apply(lambda x: ('\\newline ').join(x))\n",
    "    \n",
    "# sort by publishable name\n",
    "dfw.sort_values(['Dependent Variable', 'Instrumented'], ascending=['False', 'True'], inplace=True)\n",
    "\n",
    "dfw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to tex\n",
    "\n",
    "# get subset and convert to tex\n",
    "tablevars = dfw.og.unique() # change this\n",
    "table = dfw.loc[dfw.og.isin(tablevars), dfw.columns[:-1]]\n",
    "\n",
    "# shorten variable descriptions\n",
    "for c in table.columns[-2:]:\n",
    "    table.loc[table[c].str.contains(', unique'), c] = \\\n",
    "        table.loc[table[c].str.contains(', unique'), c].apply(lambda x: x.replace(', unique', ''))\n",
    "\n",
    "display(table.head())\n",
    "\n",
    "# convert to latex\n",
    "\n",
    "column_format='p{.25\\linewidth} p{0.3\\linewidth} '+\\\n",
    "              'p{0.22\\linewidth} p{0.22\\linewidth}'\n",
    "caption = 'LATE model controls selected via post-double-selection'\n",
    "label = 'controlvars_selected_iv'\n",
    "note = 'Controls chosen via the PDS procedure of \\\\textcite{bch2014a}. ' +\\\n",
    "    'In the \\\\textit{All Observations} model, \\\\textit{Midterm 1 score} and \\\\textit{Year = 2019} are ' +\\\n",
    "    'additionally included as controls. In the \\\\textit{Fixed Effects} model, pair fixed effects ' +\\\n",
    "    'and \\\\textit{Midterm 1 score} are included. ' +\\\n",
    "    'All control variables are measured before the start of the experiment, e.g. \\\\textit{Hours videos} is ' +\\\n",
    "    'the hours of videos watched as of the first midterm.'\n",
    "\n",
    "table = convert_to_latex(table, column_format, caption, label, note, \n",
    "                         scalewidth=True, observations=False, regnote=False)\n",
    "\n",
    "# write to tex file\n",
    "with open('../tex/tables/controlvars_selected_iv.tex', 'w') as tf:\n",
    "     tf.write(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITT coefficient estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sig_digs(num, n=3):\n",
    "    \"\"\"\n",
    "    Takes a float 'num' and returns it rounded with 'n' significant digits.\n",
    "    Returns str(float), don't use with ints.\n",
    "    \"\"\"\n",
    "    assert n > 0, 'n must be > 0'\n",
    "    if num == 0:\n",
    "        return str('0.0')\n",
    "    power = int(np.ceil(np.log10(abs(num))))\n",
    "    # return integer if number does not have digits behind decimal\n",
    "    if power >= n:\n",
    "        return str(int(round(num, n - power)))\n",
    "    # return float if number has digits behind decimal\n",
    "    else:\n",
    "        formatter = '{:.' + str(n - power) + 'f}'\n",
    "        return formatter.format(num)\n",
    "\n",
    "print(sig_digs(np.pi, 3))\n",
    "print(sig_digs(np.pi * 10000, 2))\n",
    "print(sig_digs(np.pi * 10, 2))\n",
    "print(sig_digs(np.pi * 100, 5))\n",
    "print(sig_digs(np.pi / 10, 1))\n",
    "print(sig_digs(np.pi / 100, 4))\n",
    "print(sig_digs(2.0, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape and format data\n",
    "\n",
    "def get_dfb(roundn):\n",
    "    '''\n",
    "    Takes df and dff (in memory) and returns dfb rounded to 'roundn' places.\n",
    "    dfb contains ITT coefficient estimates (betas, hence df'b').\n",
    "    '''\n",
    "    \n",
    "    for x in [df, dff]:\n",
    "        assert isinstance(x, pd.core.frame.DataFrame)\n",
    "    assert isinstance(roundn, int)\n",
    "    pass\n",
    "\n",
    "    dfb = pd.concat([df.copy().drop('ctrls', 1), dff.copy()])\n",
    "    dfb.rename(columns={'treatbeta': '1beta', \n",
    "                        'stderr': '2stderr', \n",
    "                        'meanctrl': '3mean',\n",
    "                        'N': '4N'}, inplace=True)\n",
    "\n",
    "    # get stars\n",
    "    dfb['stars'] = 0\n",
    "    dfb.loc[(abs(dfb['1beta']) - dfb['2stderr'] * 1.645) > 0, 'stars'] = 1\n",
    "    dfb.loc[(abs(dfb['1beta']) - dfb['2stderr'] * 1.96) > 0, 'stars'] = 2\n",
    "    dfb.loc[(abs(dfb['1beta']) - dfb['2stderr'] * 2.576) > 0, 'stars'] = 3\n",
    "\n",
    "    # stringify stats\n",
    "    dfb['1beta'] = dfb['1beta'].apply(lambda x: '{n:.{d}f}'.format(d=str(roundn), n=x))\n",
    "    # dfb['1_beta'] = dfb.apply(lambda x: '{:.2f}'.format(x['1_beta']) \\\n",
    "    #                           if x['depvar'][:6] != 'videos' \\\n",
    "    #                           else '{:.2f}'.format(x['1_beta']), 1)\n",
    "    dfb['1beta'] = dfb['1beta'] + dfb.stars.apply(lambda x: '*'*x)\n",
    "    dfb['2stderr'] = dfb['2stderr'].apply(lambda x: '({n:.{d}f})'.format(d=str(roundn), n=x))\n",
    "    dfb['3mean'] = dfb['3mean'].apply(lambda x: '{n:.{d}f}'.format(d=str(roundn), n=x))\n",
    "    dfb['4N'] = dfb['4N'].apply(lambda x: str(int(x)))\n",
    "    dfb.drop(['stars'], 1, inplace=True)\n",
    "\n",
    "    # reshape long (stack beta, stderr, mean, N)\n",
    "    dfb = dfb.melt(id_vars=['depvar', 'model']).sort_values(['depvar', 'model', 'variable'])\n",
    "    dfb.rename(columns={'variable': 'stat'}, inplace=True)\n",
    "    # display(dfb.head())\n",
    "\n",
    "    # reshape wide (side by side models)\n",
    "    dfb = dfb.pivot(index=['depvar', 'stat'], columns='model').reset_index()\n",
    "    dfb.columns = dfb.columns.droplevel(0)\n",
    "    dfb.columns = ['depvar', 'stat', 'FEs', 'Neyman', 'ITT', 'All']\n",
    "    dfb = dfb[['depvar', 'stat', 'ITT', 'Neyman', 'All', 'FEs']]\n",
    "\n",
    "    # replace depvar with actual names\n",
    "    dfb['og'] = dfb.depvar.copy()\n",
    "    dfb['depvar'] = dfb.depvar.apply(lambda x: name_dict.get(x))\n",
    "\n",
    "    # Get one mean per depvar\n",
    "    means = dfb.loc[dfb.stat == '3mean', ['og', 'ITT']]\n",
    "    means.columns = ['og', 'ctrlmean']\n",
    "    dfb = means.merge(dfb, on='og', how='inner')\n",
    "    return dfb\n",
    "\n",
    "\n",
    "dfb = get_dfb(2)\n",
    "dfb.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: first stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for first stage estimates only\n",
    "\n",
    "# keep only first stage vars\n",
    "table1_vars = [x for x in table_dict if table_dict.get(x) == 1]\n",
    "dfsub = dfb.loc[dfb.og.isin(table1_vars)].copy()\n",
    "\n",
    "# keep only one mean per depvar (drop rows, keep ctrlmean col)\n",
    "dfsub = dfsub.loc[dfsub.stat != '3mean']\n",
    "\n",
    "# add exam label (to split by)\n",
    "dfsub['exam'] = 'Midterm 2'\n",
    "dfsub.loc[dfsub.og.isin(['duration_final', 'duration_final_u', \\\n",
    "                         'videos_final', 'videos_final_u']), 'exam'] = 'Final'\n",
    "dfsub.sort_values(['exam', 'depvar', 'stat'], ascending=[False, False, True], inplace=True)\n",
    "\n",
    "# drop intermediate N within each exam\n",
    "keepidx = dfsub.groupby('exam', as_index=False).stat.nth(-1).index\n",
    "dfsub = dfsub.loc[(dfsub.stat != '4N') | (dfsub.index.isin(keepidx))]\n",
    "dfsub.loc[dfsub.stat == '4N', 'depvar'] = 'Observations'\n",
    "\n",
    "# add indents, remove repeats of depvar\n",
    "dfsub.loc[dfsub.depvar != 'Observations', 'depvar'] = dfsub['depvar'].mask(dfsub['depvar'].duplicated(),'')\n",
    "dfsub.loc[dfsub.og.isin(['videos_mid2', 'videos_final']) & ~dfsub.depvar.isin(['Observations', '']), 'depvar'] = 'Videos'\n",
    "dfsub.loc[dfsub.og.isin(['videos_mid2_u', 'videos_final_u']) & ~dfsub.depvar.isin(['Observations', '']), 'depvar'] = 'Unique videos'\n",
    "dfsub.loc[dfsub.og.isin(['duration_mid2', 'duration_final']) & ~dfsub.depvar.isin(['Observations', '']), 'depvar'] = 'Hours of videos'\n",
    "dfsub.loc[dfsub.og.isin(['duration_mid2_u', 'duration_final_u']) & ~dfsub.depvar.isin(['Observations', '']), 'depvar'] = 'Hours of unique videos'\n",
    "dfsub.loc[~dfsub.depvar.isin(['Observations', '']), 'depvar'] = dfsub.depvar.apply(lambda x: '\\\\indentrow{' + x + '} ')\n",
    "\n",
    "# remove control mean duplicates and unecessary cols\n",
    "dfsub['ctrlmean'] = dfsub.ctrlmean.mask(dfsub.ctrlmean.duplicated(),'')\n",
    "dfsub.drop(['stat', 'og', 'exam'], 1, inplace=True)\n",
    "\n",
    "# append bottom of table info\n",
    "dfsub.reset_index(drop=True, inplace=True)\n",
    "dfsub.loc[len(dfsub), :] = ['Treatment assignment controls', '', 'Yes', 'No', 'Yes', 'Yes']\n",
    "dfsub.loc[len(dfsub), :] = ['Demographic controls', '', 'No', 'No', 'Yes', 'Yes']\n",
    "dfsub.loc[len(dfsub), :] = ['Pair Fixed Effects', '', 'No', 'No', 'No', 'Yes']\n",
    "\n",
    "# rename cols\n",
    "dfsub.rename(columns={'depvar': '', 'ctrlmean': 'Control Mean', 'ITT': '(1)', 'Neyman': '(2)', \n",
    "                      'All': '(3)', 'FEs': '(4)'}, inplace=True)\n",
    "\n",
    "display(dfsub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate to tex\n",
    "\n",
    "column_format='m{0.35\\\\linewidth} *{5}{>{\\\\centering\\\\arraybackslash}m{0.1\\\\linewidth}}'\n",
    "caption = 'Effects of Grade Incentive on Video Watching'\n",
    "label = 'firststage_table'\n",
    "note = 'This table reports coefficients on $Incentive_i$ from Equations \\\\ref{itt_spec} ' +\\\n",
    "    'and TBD. Model (1) contains linear controls midterm 1 score and year; (2) is ' +\\\n",
    "    'the difference in means and standard errors calculated using the repeated sampling ' +\\\n",
    "    'framework of Neyman (1923); (3) and (4) use the post-double-selection (PDS) procedure of ' +\\\n",
    "    '\\\\textcite{bch2014a} to select control variables then estimate treatment effects and ' +\\\n",
    "    'standard errors. The control variables selected using PDS are listed in Table ' +\\\n",
    "    '\\\\ref{controlvars_selected_itt}. Models (2) and (4) contain only students whose matched-' +\\\n",
    "    'pair did not attrite from the experiment. '\n",
    "# note += 'The \\textit{video} outcome variables comprise course-relevant videos.' +\\\n",
    "#     'If the same video is watched twice, the longest duration is recorded. '\n",
    "note += '\\\\textit{Control Mean} is the mean for the ' +\\\n",
    "    'Control students included in models (1) and (3), which is nearly identical ' +\\\n",
    "    'to the mean for the Control students included in models (2) and (4). '\n",
    "\n",
    "table = convert_to_latex(dfsub, column_format, caption, label, note, scalewidth=False, observations=False)\n",
    "\n",
    "# add space between variables and table desc\n",
    "# first, get indicies\n",
    "import re\n",
    "idx = [m.start() for m in re.finditer('\\\\\\indentrow{', table)]\n",
    "# third, add to table in reverse order\n",
    "for i in idx[:-4:-1]:\n",
    "    table = table[:i] + '\\\\customlinespace ' + table[i:]\n",
    "insert = '\\\\midrule \\n \\\\multicolumn{6}{l}{\\\\textbf{Panel B}: By Final Exam} \\\\\\ \\n'\n",
    "table = table[:idx[4]] + insert + table[idx[4]:] \n",
    "for i in idx[3:0:-1]:\n",
    "    table = table[:i] + '\\\\customlinespace ' + table[i:]\n",
    "insert = '\\\\multicolumn{6}{l}{\\\\textbf{Panel A}: By Midterm 2} \\\\\\ \\n'\n",
    "table = table[:idx[0]] + insert + table[idx[0]:]\n",
    "\n",
    "# add \\midrule before 'Observations'\n",
    "table = table.replace('Observations', '\\\\midrule \\n Observations')\n",
    "\n",
    "# write to tex file\n",
    "with open('../tex/tables/firststage.tex', 'w') as tf:\n",
    "     tf.write(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: second stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redo dfb with different rounding\n",
    "\n",
    "dfb = get_dfb(3)\n",
    "\n",
    "dfb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# shape and format data, LATEs\n",
    "\n",
    "def get_dfl(roundn):\n",
    "    '''\n",
    "    Takes dfiv and dflate (in memory) and returns dfl rounded to 'roundn' places.\n",
    "    dfl contains LATE coefficient estimates (LATE, hence df'l').\n",
    "    '''\n",
    "\n",
    "    dfl = pd.concat([dfiv.copy().drop('ctrls', 1), dflate.copy()])\n",
    "    dfl.rename(columns={'treatbeta': '1beta', \n",
    "                        'stderr': '2stderr', \n",
    "                        'meanctrl': '3mean',\n",
    "                        'N': '4N'}, inplace=True)\n",
    "\n",
    "    # get stars\n",
    "    dfl['stars'] = 0\n",
    "    dfl.loc[(abs(dfl['1beta']) - dfl['2stderr'] * 1.645) > 0, 'stars'] = 1\n",
    "    dfl.loc[(abs(dfl['1beta']) - dfl['2stderr'] * 1.96) > 0, 'stars'] = 2\n",
    "    dfl.loc[(abs(dfl['1beta']) - dfl['2stderr'] * 2.576) > 0, 'stars'] = 3\n",
    "\n",
    "    # stringify stats\n",
    "    dfl['1beta'] = dfl['1beta'].apply(lambda x: '{n:.{d}f}'.format(d=str(roundn), n=x)) \\\n",
    "                                + dfl.stars.apply(lambda x: '*'*x)\n",
    "    dfl['2stderr'] = dfl['2stderr'].apply(lambda x: '({n:.{d}f})'.format(d=str(roundn), n=x))\n",
    "    dfl['3mean'] = dfl['3mean'].apply(lambda x: '{n:.{d}f}'.format(d=str(roundn), n=x))\n",
    "    dfl['4N'] = dfl['4N'].apply(lambda x: str(int(x)))\n",
    "    dfl.drop('stars', 1, inplace=True)\n",
    "\n",
    "    # get instrumented var and models\n",
    "    dfl['Instrumented'] = dfl.model.apply(lambda x: x[-1])\n",
    "    dfl['model'] = dfl.model.apply(lambda x: x[:-2])\n",
    "\n",
    "    # reshape long (stack beta, stderr, mean, N)\n",
    "    dfl = dfl.melt(id_vars=['depvar', 'model', 'Instrumented']).\\\n",
    "        sort_values(['depvar', 'Instrumented', 'model', 'variable'], ascending=[False, True, True, True])\n",
    "    dfl.rename(columns={'variable': 'stat'}, inplace=True)\n",
    "\n",
    "    # reshape wide (side by side models)\n",
    "    dfl = dfl.pivot(index=['depvar', 'Instrumented', 'stat'], columns='model').reset_index()\n",
    "    dfl.columns = dfl.columns.droplevel(0)\n",
    "    dfl.columns = ['depvar', 'Instrumented', 'stat', 'Neyman', 'All', 'FEs', 'ITT']\n",
    "    dfl = dfl[['depvar', 'Instrumented', 'stat', 'ITT', 'Neyman', 'All', 'FEs']]\n",
    "\n",
    "    # replace depvar with actual names\n",
    "    dfl['og'] = dfl.depvar.copy()\n",
    "    dfl['depvar'] = dfl.depvar.apply(lambda x: name_dict.get(x))\n",
    "    \n",
    "    return dfl\n",
    "\n",
    "dfl = get_dfl(3)\n",
    "dfl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack with dfb (ITT estimates)\n",
    "\n",
    "# keep only second stage vars\n",
    "table2_vars = [x for x in table_dict if table_dict.get(x) == 2]\n",
    "dfsub = dfb.loc[dfb.og.isin(table2_vars)].copy()\n",
    "\n",
    "# add 'instrumented' col (for stacking), drop ctrlmean\n",
    "dfsub.insert(1, 'Instrumented', 'z')\n",
    "dfsub.drop('ctrlmean', 1, inplace=True)\n",
    "\n",
    "# combine the two dfs and sort, drop mean\n",
    "dfsub = pd.concat([dfsub, dfl])\n",
    "dfsub = dfsub.loc[dfsub.stat != '3mean']\n",
    "dfsub.sort_values(['depvar', 'Instrumented', 'stat'], \n",
    "                  ascending=[False, False, True], inplace=True)\n",
    "\n",
    "# drop intermediate N within each exam\n",
    "keepidx = dfsub.groupby('og', as_index=False).stat.nth(-1).index\n",
    "dfsub = dfsub.loc[(dfsub.stat != '4N') | (dfsub.index.isin(keepidx))]\n",
    "dfsub.loc[dfsub.stat == '4N', 'Instrumented'] = 'Observations'\n",
    "\n",
    "# name instruments\n",
    "dfsub.Instrumented.replace({'z': 'RF: Incentive', 'v': '2SLS: 10 Videos', 'd': '2SLS: 1 Hour of Videos'}, inplace=True)\n",
    "dfsub.loc[dfsub.stat != '4N', 'Instrumented'] = dfsub.Instrumented.apply(lambda x: '\\\\indentrow{' + x + '} ')\n",
    "\n",
    "# remove Instrumented duplicates and unnecessary cols\n",
    "for v in dfsub.og.unique():\n",
    "    dfsub.loc[dfsub.og == v, 'Instrumented'] = dfsub.loc[dfsub.og == v].\\\n",
    "        Instrumented.mask(dfsub.loc[dfsub.og == v].Instrumented.duplicated(),'')\n",
    "dfsub.drop(['depvar', 'stat', 'og'], 1, inplace=True)\n",
    "\n",
    "# rename cols\n",
    "dfsub.rename(columns={'Instrumented': '', 'ITT': '(1)', 'Neyman': '(2)', \n",
    "                      'All': '(3)', 'FEs': '(4)'}, inplace=True)\n",
    "\n",
    "# append bottom of table info\n",
    "dfsub.reset_index(drop=True, inplace=True)\n",
    "dfsub.loc[len(dfsub), :] = ['Treatment assignment controls', 'Yes', 'No', 'Yes', 'Yes']\n",
    "dfsub.loc[len(dfsub), :] = ['Demographic controls', 'No', 'No', 'Yes', 'Yes']\n",
    "dfsub.loc[len(dfsub), :] = ['Pair Fixed Effects', 'No', 'No', 'No', 'Yes']\n",
    "\n",
    "dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate to tex\n",
    "\n",
    "column_format='m{0.35\\\\linewidth} *{4}{>{\\\\centering\\\\arraybackslash}m{0.1\\\\linewidth}}'\n",
    "caption = 'Effects of Videos on Grades'\n",
    "label = 'secondstage_table'\n",
    "note = 'This table reports coefficients on $Incentive_i$ from Equation \\\\ref{late_spec} and ' +\\\n",
    "    '$Video_i$ from Equation TBD. Test scores are measured in standard deviation units. ' +\\\n",
    "    'Model (1) contains linear controls midterm 1 score and year; (2) is ' +\\\n",
    "    'the difference in means and standard errors calculated using the repeated sampling ' +\\\n",
    "    'framework of Neyman (1923); (3) and (4) use the post-double-selection (PDS) procedure of ' +\\\n",
    "    '\\\\textcite{bch2014a} to select control variables then estimate treatment effects and ' +\\\n",
    "    'standard errors. The control variables selected using PDS are listed in Table ' +\\\n",
    "    '\\\\ref{controlvars_selected_itt}. Models (2) and (4) contain only students whose matched-' +\\\n",
    "    'pair did not attrite from the experiment.'\n",
    "\n",
    "table = convert_to_latex(dfsub, column_format, caption, label, note, scalewidth=False, observations=False)\n",
    "\n",
    "# first, get indicies\n",
    "import re\n",
    "idx = [m.start() for m in re.finditer('\\\\\\indentrow{', table)]\n",
    "# third, add to table in reverse order\n",
    "for i in idx[:-3:-1]:\n",
    "    table = table[:i] + '\\\\customlinespace ' + table[i:]\n",
    "insert = '\\\\midrule \\n \\\\multicolumn{5}{l}{\\\\textbf{Panel B}: Final Exam Score} \\\\\\ \\n'\n",
    "table = table[:idx[3]] + insert + table[idx[3]:] \n",
    "for i in idx[2:0:-1]:\n",
    "    table = table[:i] + '\\\\customlinespace ' + table[i:]\n",
    "insert = '\\\\multicolumn{5}{l}{\\\\textbf{Panel A}: Midterm 2 Score} \\\\\\ \\n'\n",
    "table = table[:idx[0]] + insert + table[idx[0]:] \n",
    "\n",
    "# add \\midrule before 'Observations'\n",
    "table = table.replace('Observations', '\\\\midrule \\n Observations')\n",
    "\n",
    "# write to tex file\n",
    "with open('../tex/tables/secondstage.tex', 'w') as tf:\n",
    "     tf.write(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table: spillovers to grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dfb\n",
    "\n",
    "dfb = get_dfb(2)\n",
    "dfb.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table for spillover vars only\n",
    "\n",
    "def shape_dfb(varlist, N_list=['']):\n",
    "    '''\n",
    "    Takes dfb (in memory), restricts it to varlist and shapes it,\n",
    "    returning shaped dfsub.\n",
    "    Orders by varlist.\n",
    "    \n",
    "    N_list: list of vars in varlist s.t. observations are printed.\n",
    "    '''\n",
    "    for v in [varlist, N_list]:\n",
    "        assert isinstance(v, list)\n",
    "    pass\n",
    "\n",
    "    # keep only vars in varlist\n",
    "    dfsub = dfb.loc[dfb.og.isin(varlist)].copy()\n",
    "\n",
    "    # keep only one mean per depvar (drop rows, keep ctrlmean col), sort\n",
    "    dfsub = dfsub.loc[dfsub.stat != '3mean'].sort_values(['depvar', 'stat'], ascending=[False, True]).reset_index(drop=True)\n",
    "    \n",
    "    # order by varlist\n",
    "    sorterIndex = dict(zip(varlist, range(len(varlist))))\n",
    "    dfsub['rank'] = dfsub['og'].map(sorterIndex)\n",
    "    dfsub = dfsub.sort_values(['rank', 'stat']).reset_index(drop=True)\n",
    "\n",
    "    # drop intermediate N\n",
    "    dfsub = dfsub.loc[(dfsub.stat != '4N') | (dfsub.index == max(dfsub.index)) | \\\n",
    "                      ((dfsub.stat == '4N') & (dfsub.og.isin(N_list)))]\n",
    "    dfsub.loc[dfsub.stat == '4N', 'depvar'] = 'Observations'\n",
    "\n",
    "    # remove control mean duplicates and unecessary cols\n",
    "    dfsub['ctrlmean'] = dfsub.ctrlmean.mask(dfsub.ctrlmean.duplicated(),'')\n",
    "    dfsub.loc[dfsub.depvar != 'Observations', 'depvar'] = dfsub.loc[dfsub.depvar != 'Observations'].depvar.mask(dfsub.depvar.duplicated(),'')\n",
    "    dfsub.drop(['stat', 'og', 'rank'], 1, inplace=True)\n",
    "    dfsub = dfsub[['depvar', 'ctrlmean', 'ITT', 'Neyman', 'All', 'FEs']]\n",
    "    \n",
    "    # append bottom of table info\n",
    "    dfsub = dfsub.reset_index(drop=True)\n",
    "    dfsub.loc[len(dfsub), :] = ['Treatment assignment controls', '', 'Yes', 'No', 'Yes', 'Yes']\n",
    "    dfsub.loc[len(dfsub), :] = ['Demographic controls', '', 'No', 'No', 'Yes', 'Yes']\n",
    "    dfsub.loc[len(dfsub), :] = ['Pair Fixed Effects', '', 'No', 'No', 'No', 'Yes']\n",
    "\n",
    "    # rename cols\n",
    "    dfsub.rename(columns={'depvar': '', 'ctrlmean': 'Control Mean', 'ITT': '(1)', 'Neyman': '(2)', \n",
    "                          'All': '(3)', 'FEs': '(4)'}, inplace=True)\n",
    "    \n",
    "    return dfsub\n",
    "\n",
    "table3_vars = ['gpa_letter',\n",
    "               'gpa_letter_sans100a',\n",
    "               'gpa_letter_sansecon',\n",
    "               'gpa_econ_sans100a',\n",
    "               'nclass_p',\n",
    "               'nclass_np',\n",
    "               'nclass_w',\n",
    "               'letter_option',\n",
    "               'pclass_letter',\n",
    "               'pclass_pnp']\n",
    "gpalist = [x for x in table3_vars if x.find('gpa') > -1]\n",
    "dfsub = shape_dfb(table3_vars, gpalist)\n",
    "dfsub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# translate to tex\n",
    "\n",
    "column_format='m{0.44\\\\linewidth} *{5}{>{\\\\centering\\\\arraybackslash}m{0.1\\\\linewidth}}'\n",
    "caption = 'Spillover Effects of Incentive on Other Course Grades'\n",
    "label = 'spillover_grades'\n",
    "note = 'This table reports coefficients on $Incentive_i$ from Equations \\\\ref{itt_spec} ' +\\\n",
    "    'and TBD. Model (1) contains linear controls midterm 1 score and year; (2) is ' +\\\n",
    "    'the difference in means and standard errors calculated using the repeated sampling ' +\\\n",
    "    'framework of Neyman (1923); (3) and (4) use the post-double-selection (PDS) procedure of ' +\\\n",
    "    '\\\\textcite{bch2014a} to select control variables then estimate treatment effects and ' +\\\n",
    "    'standard errors. The control variables selected using PDS are listed in Table ' +\\\n",
    "    '\\\\ref{controlvars_selected_itt}. Models (2) and (4) contain only students whose matched-' +\\\n",
    "    'pair did not attrite from the experiment. '\n",
    "note += 'GPA is measured on a 4.0 scale and is only affected by courses taken for a letter grade. ' +\\\n",
    "    'Courses taken for Pass/No Pass (P/NP) have no bearing on GPA, nor do withdrawn courses. '\n",
    "\n",
    "note += '\\\\textit{Control Mean} is the mean for the ' +\\\n",
    "    'Control students included in models (1) and (3), which is nearly identical ' +\\\n",
    "    'to the mean for the Control students included in models (2) and (4).'\n",
    "\n",
    "table = convert_to_latex(dfsub, column_format, caption, label, note, scalewidth=True, observations=False)\n",
    "\n",
    "# add panel headings\n",
    "idx = table.find('All classes')\n",
    "insert = '\\\\multicolumn{6}{l}{\\\\textbf{Panel A}: Effects on Term GPA} \\\\\\ \\n'\n",
    "table = table[:idx] + insert + table[idx:] \n",
    "\n",
    "idx = table.find('Num. classes passed')\n",
    "insert = '\\\\midrule \\n \\\\multicolumn{6}{l}{\\\\textbf{Panel B}: Effects on classes passed} \\\\\\ \\n'\n",
    "table = table[:idx] + insert + table[idx:] \n",
    "\n",
    "idx = table.find('Letter grade in Micro A')\n",
    "insert = '\\\\midrule \\n \\\\multicolumn{6}{l}{\\\\textbf{Panel C}: Effects on class grade type} \\\\\\ \\n'\n",
    "table = table[:idx] + insert + table[idx:] \n",
    "\n",
    "# remove first 4 \"observations\"\n",
    "idx = [m.start() for m in re.finditer('Observations', table)]\n",
    "for i in idx[3::-1]:\n",
    "    table = table[:i] + table[i+len('Observations'):]\n",
    "    \n",
    "\n",
    "def add_indents(ttable, varlist):\n",
    "    \"\"\"\n",
    "    Adds \\\\customlinespace \\\\indentrow{var} for var in varlist to ttable, a tex table.\n",
    "    \"\"\"\n",
    "    assert isinstance(ttable, str)\n",
    "    assert isinstance(varlist, list)\n",
    "    assert all([isinstance(v, str) for v in varlist])\n",
    "    pass\n",
    "\n",
    "    import re\n",
    "    for v in varlist:\n",
    "        idx = [m.start() for m in re.finditer(v + ' &', ttable)]\n",
    "        for i in idx[::-1]:\n",
    "            if v[0] == '\\\\':\n",
    "                i -= 1\n",
    "            ttable = ttable[:i] + '\\\\customlinespace \\\\indentrow{' + v + '}' + ttable[i + len(v):]\n",
    "\n",
    "    return ttable\n",
    "\n",
    "# add indents\n",
    "varlist = [x for x in dfsub.iloc[:-4, 0].unique() if x not in ['', 'Observations']]\n",
    "table = add_indents(table, varlist)\n",
    "\n",
    "# add \\midrule before last 'Observations'\n",
    "idx = table.rfind('Observations')\n",
    "table = table[:idx] + '\\\\midrule \\n' + table[idx:]\n",
    "\n",
    "\n",
    "# write to tex file\n",
    "with open('../tex/tables/spillover_grades.tex', 'w') as tf:\n",
    "     tf.write(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "461.4px",
    "left": "22px",
    "top": "110.8px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
